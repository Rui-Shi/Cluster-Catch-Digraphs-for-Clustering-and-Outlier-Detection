labels_list
tt1 = Sys.time()
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
source("G:/code_working_folder/general functions/ratio1.R")
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
library(dbscan)
d = 2
iteN = 1000
cores = detectCores()
cores = 24 # 13900K
# simulation settings
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
MinPts = 4 # The minimum number of points required within the eps radius to form a dense region.
cont = 0.09 # the average contamination level
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
cl <- makeCluster(cores)
registerDoParallel(cl)
labels_list = foreach(x=data.list,.packages = c("MASS","cluster","dbscan")) %dopar% DBSCAN(x, MinPts, cont)
stopCluster(cl)
count.result = foreach(x=1:iteN,.combine = rbind) %do% count_DBSCAN2(data.num[[x]][1], data.num[[x]][2], labels_list[[x]])
mean = c(mean(count.result[,1]),mean(count.result[,2]),mean(count.result[,3]),mean(count.result[,4]))
print(paste("DBSCAN: the mean TPR is", mean[1],",","the mean TNR", mean[2],",","the mean BA", mean[3],",","the mean F2", mean[4]))
tt2 = Sys.time()
tt2 - tt1
tt1 = Sys.time()
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
library(dbscan)
ratio = c(1.000000, 1.024079, 1.068926, 1.163903, 1.291596)
d = 3
k = 4 # the value of MinPTS for DBSCAN
quant = 0.09 # noise level
iteN = 1000
cores = detectCores()
# cores = 24 # 13900K
# simulation settings
kappa1 = 6
mu1 = 36.7*ratio[2]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = 36.7*ratio[2]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
perf = sapply(1:iteN, function(x){
datax = data.list[[x]]
dist_M = as.matrix(dist(datax))
k_dist = apply(dist_M, 1, function(row){  # compute the k-distance for each point
return(sort(row)[k+1])
})
eps = quantile(k_dist, 1-quant) # find the eps of DBSCAN based on noise level
result = dbscan(datax, eps, k) # conduct DBSCAN
clusters = result$cluster  # count SR and FP
FP = sum(clusters[1:data.num[[x]][1]]==0)/data.num[[x]][1]
SR = sum(clusters[-c(1:data.num[[x]][1])]==0)/data.num[[x]][2]
return(c(SR,FP))
})
result_mean = apply(perf, 1, mean)
print(result_mean)
tt2 = Sys.time()
tt2 - tt1
ratio
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
source("G:/code_working_folder/general functions/ratio1.R")
source("G:/code_working_folder/Algo_Compare/DBSCAN/DBSCAN.R")
ratio[5]
setwd("G:/code_working_folder/Algo_Compare/DBSCAN/Simulation/Complex_Clusters/Matern")
tt1 = Sys.time()
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
source("G:/code_working_folder/general functions/ratio2.R")
source("G:/code_working_folder/Algo_Compare/DBSCAN/DBSCAN.R")
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
library(dbscan)
d = 100
iteN = 1000
cores = detectCores()
cores = 24 # 13900K
# simulation settings
kappa1 = 0
mu1 = ratio[7]
expand1 = 0
r = 0.1
kappa2 = 6
scale = 0.005
mu2 = ratio[7]
expand2 = 0
slen = 1
kappa_O = 20
MinPts = 4 # The minimum number of points required within the eps radius to form a dense region.
cont = 0.09 # the average contamination level
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
tt1 = Sys.time()
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
source("G:/code_working_folder/general functions/ratio1.R")
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
library(dbscan)
d = 2
K = c(11:30) # range of minPTS for LOF
iteN = 1000
cores = detectCores()
threshes = seq(1.2,2.5,0.1) # threshold for LOF
cores = 24 # 13900K
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
perf = sapply(threshes, function(thresh){
result_Mat = sapply(1:iteN, function(x){
LOF_Mat = sapply(K, function(k){
LOF = lof(data.list[[x]],k)
return(LOF)
})
LOF_Group = apply(LOF_Mat, 1, function(row){
if (any(row>thresh)) {
return(2) # 2 for outliers
} else {
return(1) # 1 for usual data points
}
})
TNP = 1-sum(LOF_Group[1:data.num[[x]][1]]==2)/data.num[[x]][1]
TPR = sum(LOF_Group[-c(1:data.num[[x]][1])]==2)/data.num[[x]][2]
BA = (TNR+TPR)/2
recall = TPR
precision = n0*TPR/(n0*TPR+(1-TNR)*(n-n0))
F2 = 5*precision*recall/(4*precision+recall)
if(is.na(F2)) F2=0
return(c(TPR=TPR,TNR=TNR,BA=BA,F2=F2))
})
result_mean = apply(result_Mat, 1, mean)
return(result_mean)
})
tt1 = Sys.time()
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
source("G:/code_working_folder/general functions/ratio1.R")
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
library(dbscan)
d = 2
K = c(11:30) # range of minPTS for LOF
iteN = 1000
cores = detectCores()
threshes = seq(1.2,2.5,0.1) # threshold for LOF
cores = 24 # 13900K
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
perf = sapply(threshes, function(thresh){
result_Mat = sapply(1:iteN, function(x){
LOF_Mat = sapply(K, function(k){
LOF = lof(data.list[[x]],k)
return(LOF)
})
LOF_Group = apply(LOF_Mat, 1, function(row){
if (any(row>thresh)) {
return(2) # 2 for outliers
} else {
return(1) # 1 for usual data points
}
})
TNR = 1-sum(LOF_Group[1:data.num[[x]][1]]==2)/data.num[[x]][1]
TPR = sum(LOF_Group[-c(1:data.num[[x]][1])]==2)/data.num[[x]][2]
BA = (TNR+TPR)/2
recall = TPR
precision = n0*TPR/(n0*TPR+(1-TNR)*(n-n0))
F2 = 5*precision*recall/(4*precision+recall)
if(is.na(F2)) F2=0
return(c(TPR=TPR,TNR=TNR,BA=BA,F2=F2))
})
result_mean = apply(result_Mat, 1, mean)
return(result_mean)
})
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
source("G:/code_working_folder/general functions/Strauss.R")
source("G:/code_working_folder/general functions/count.R")
set.seed(123)
t1 = Sys.time()
cores = detectCores()
# cores = 24 # for 13900K
LB = 11 # Lower bound for MinPts
UB = 30 # Upper bound for MinPts
Thresh = 1.5 # threshhold for outliers
# d: dimension
# cont: contamination level
# n0: number of outliers
# n: size of the dataset
# n1,n2,...: the size of each clusters
# iteN: number of experiments
n = 50
d = 2
cont = 0.05
iteN = 1000 # the number of simulated data set.
cls_dis = 3 # the distances between each cluster center
otl_dis = 2 # the minimal distances of outliers to cluster centers
# the min and max of the radii of clusters
r_min = 0.7
r_max = 1.3
# simulate two clusters of equal size within two unit balls centered at (3,3) and (3+cls_dis,3)
# the radius of clusters are random numbers between 0.7-1.3
mu1 = rep(3,d)
mu2 = c(3+cls_dis,rep(3,d-1))
mu = rbind(mu1,mu2)
mu = apply(mu,2,mean)
n1 = round(n*(1-cont)*0.5)
n2 = round(n*(1-cont)*0.5)
n0 = round(n*cont)
set.seed(123)
data.list = lapply(1:iteN, function(x){
data1 = rpoisball.unit(n1,d)*runif(1,r_min,r_max) + matrix(rep(mu1,n1),ncol=d,byrow=T)
data2 = rpoisball.unit(n2,d)*runif(1,r_min,r_max) + matrix(rep(mu2,n2),ncol=d,byrow=T)
i = 0
outlier = NULL
while(i < n0){
temp = rpoisball.unit(1,d)*5 + mu
r1 = sqrt(sum((temp-mu1)^2))
r2 = sqrt(sum((temp-mu2)^2))
if(r1 > otl_dis & r2 > otl_dis){
outlier = rbind(outlier,temp)
i = i + 1
}
}
rownames(outlier) = NULL
return(rbind(data1,data2,outlier))
})
cl <- makeCluster(cores)
registerDoParallel(cl)
scores = foreach(x=data.list,.packages = c("MASS","cluster","dbscan")) %dopar% LOF(x,LB,UB)
stopCluster(cl)
count.result = foreach(x=1:iteN,.combine = rbind) %do% count_scores(x=x,scores=scores,threshold=Thresh, n=n, n0=n0)
mean = c(mean(count.result[,1]),mean(count.result[,2]),mean(count.result[,3]),mean(count.result[,4]))
print(paste("LOF: the mean TPR is", mean[1],",","the mean TNR", mean[2],",","the mean BA", mean[3],",","the mean F2", mean[4]))
t2 = Sys.time()
t2-t1
save.image("G:/code_working_folder/Algo_Compare/LOF/Simulation/Uniform/2d/2d_2cls_n50_cont5%.RData")
scores
count_scores
tt1 = Sys.time()
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
source("G:/code_working_folder/general functions/Strauss.R")
source("G:/code_working_folder/general functions/count.R")
set.seed(123)
t1 = Sys.time()
cores = detectCores()
cores = 24 # for 13900K
LB = 11 # Lower bound for MinPts
UB = 30 # Upper bound for MinPts
Thresh = 1.5 # threshhold for outliers
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
cl <- makeCluster(cores)
registerDoParallel(cl)
scores = foreach(x=data.list,.packages = c("MASS","cluster","dbscan")) %dopar% LOF(x,LB,UB)
stopCluster(cl)
count.result = foreach(x=1:iteN,.combine = rbind) %do% count_scores1(x=x,scores=scores,threshold=Thresh)
mean = c(mean(count.result[,1]),mean(count.result[,2]),mean(count.result[,3]),mean(count.result[,4]))
print(paste("LOF: the mean TPR is", mean[1],",","the mean TNR", mean[2],",","the mean BA", mean[3],",","the mean F2", mean[4]))
t2 = Sys.time()
t2-t1
print(paste("LOF: the mean TPR is", result_mean[1],",","the mean TNR", result_mean[2],",","the mean BA", result_mean[3],",","the mean F2", result_mean[4]))
tt2 = Sys.time()
tt2 - tt1
count.result
mean
tt1 = Sys.time()
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
source("G:/code_working_folder/general functions/Strauss.R")
source("G:/code_working_folder/general functions/count.R")
set.seed(123)
t1 = Sys.time()
cores = detectCores()
cores = 24 # for 13900K
LB = 11 # Lower bound for MinPts
UB = 30 # Upper bound for MinPts
Thresh = 1.5 # threshhold for outliers
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
cl <- makeCluster(cores)
registerDoParallel(cl)
scores = foreach(x=data.list,.packages = c("MASS","cluster","dbscan")) %dopar% LOF(x,LB,UB)
stopCluster(cl)
count.result = foreach(x=1:iteN,.combine = rbind) %do% count_scores1(x=x,scores=scores,threshold=Thresh)
mean = c(mean(count.result[,1]),mean(count.result[,2]),mean(count.result[,3]),mean(count.result[,4]))
print(paste("LOF: the mean TPR is", mean[1],",","the mean TNR", mean[2],",","the mean BA", mean[3],",","the mean F2", mean[4]))
tt2 = Sys.time()
tt2 - tt1
d
setwd("G:/code_working_folder/Algo_Compare/LOF/Simulation/Complex_Clusters/Matern")
tt1 = Sys.time()
library(parallel)
library(doParallel)
library(MASS)
library(igraph)
source("G:/code_working_folder/Algo_Compare/LOF/LOF.R")
source("G:/code_working_folder/general functions/count.R")
source("G:/code_working_folder/general functions/ratio1.R")
source("G:/code_working_folder/general functions/Uni-Gau_cls.R")
set.seed(123)
t1 = Sys.time()
cores = detectCores()
cores = 24 # for 13900K
LB = 11 # Lower bound for MinPts
UB = 30 # Upper bound for MinPts
Thresh = 1.5 # threshhold for outliers
iteN = 1000 # the number of simulated data set.
d=2
kappa1 = 6
mu1 = ratio[1]
expand1 = 0
r = 0.1
kappa2 = 0
scale = 0.005
mu2 = ratio[1]
expand2 = 0
slen = 1
kappa_O = 20
# simulate clusters of random sizes and positions
set.seed(1234)
data.listNum = lapply(1:iteN, function(x){
data_simu =  Uni.Gau_cls(d, kappa1, r, mu1, expand1, kappa2, scale, mu2, expand2, slen, kappa_O)
cls1 = data_simu$Matérn_children
cls2 = data_simu$Thomas_children
cls3 = data_simu$noise
outlier = data_simu$Outlier
return(c(data = list(rbind(cls1, cls2, cls3, outlier)), num = list(data_simu$num)))
})
data.list = lapply(1:iteN, function(x){
return(data.listNum[[x]]$data)
})
data.num = lapply(1:iteN, function(x){
return(data.listNum[[x]]$num)
})
cl <- makeCluster(cores)
registerDoParallel(cl)
scores = foreach(x=data.list,.packages = c("MASS","cluster","dbscan")) %dopar% LOF(x,LB,UB)
installed.packages()
library(installr)
install.packages("installr")
updateR()
library(installr)
updateR()
updateR()
